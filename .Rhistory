ylab = "Number of Reproductive Flies")
?chisq.test
reproductive.temp <- matrix (,2,2)
reproductive.temp[1,1] <- 32
reproductive.temp[1,2] <- 18
reproductive.temp[2,1] <- 20
reproductive.temp[2,2] <- 30
colnames(reproductive.temp) <- c('Sterile', 'Fertile')
rownames(reproductive.temp) <- c('France', 'India')
mosaicplot(reproductive.temp,
main = "Drosophila Sterility in Warmer Climates",
color = c('blue', 'yellow'),
xlab = "Country",
ylab = "Number of Reproductive Flies")
View(reproductive.temp)
reproductive.temp <- matrix (,2,2)
reproductive.temp[1,1] <- 32
reproductive.temp[1,2] <- 18
reproductive.temp[2,1] <- 20
reproductive.temp[2,2] <- 30
colnames(reproductive.temp) <- c('Sterile', 'Fertile')
rownames(reproductive.temp) <- c('France', 'India')
mosaicplot(reproductive.temp,
main = "Drosophila Sterility in Warmer Climates",
color = c('blue', 'yellow'),
xlab = "Country",
ylab = "Number of Reproductive Flies")
chisq.test(reproductive.temp)
#
a <- 20
b <- 32
c <- 30
d <- 18
p1 <- a / (a + c)
p2 <- b / (b + d)
RR <- p1/p2
SE <- sqrt(1/a + 1/b - 1/(a+c) - 1/(b+d))
low <- exp(log(RR) - 1.96*SE)
high <- exp(log(RR) + 1.96*SE)
#PROBLEM 1
#how many wrinkled pea plants will a student see in her
#12 plants?
W <- 12*0.25
#What is the standard deviation of the proportion of wrinkled pea
#plants per student.
sqrt((0.25*0.75)/12)
0.125^2
#What is the standard deviation of the proportion of wrinkled pea
#plants per student. Answer:
sqrt((0.25*0.75)/12)
#What is the variance of the proportion of wrinkled pea plants per
#student? Answer:
0.125^2
#Predict what proportion of the students saw exactly two wrinkled
#pea plants in their sample. Answer:
dbinom(2,12, p=0.25)
deaths <- as.data.frame(matrix( ,1,3))
deaths <- as.data.frame(matrix( ,1,3))
colnames(deaths) <- ("0 degrees", "20 degrees", "40 degrees")
colnames(deaths) <- ("0 degrees" "20 degrees" "40 degrees")
deaths[1, ] <- c(30,15,8)
chisq.test(deaths[1, ])
(deaths[1,1])/(sum(deaths[1, ]))
proportion.vertical.deaths <- (deaths[1,1])/(sum(deaths[1, ]))
RR <- p1/p2
low <- exp(log(RR) - 1.96*SE)
high <- exp(log(RR) + 1.96*SE)
1.96*SE
#PROBLEM 4
#Test whether the pattern of health deterioration was different between
#the two groups of women
x <- data.frame("Marked Det" = c(28,7)
"Moderate Det" = c(47,31)
"No Det" = c(57,60))
#PROBLEM 4
#Test whether the pattern of health deterioration was different between
#the two groups of women
x <- data.frame("Marked Det" = c(28,7),
"Moderate Det" = c(47,31),
"No Det" = c(57,60))
rownames(x) <- c('Experimental', 'Control')
chisq.test(x)
mosaicplot(x, main = NULL)
reproductive.temp <- matrix ( ,2,2)
reproductive.temp[1,1] <- 32
reproductive.temp[1,2] <- 18
reproductive.temp[2,1] <- 20
reproductive.temp[2,2] <- 30
colnames(reproductive.temp) <- c('Sterile', 'Fertile')
rownames(reproductive.temp) <- c('France', 'India')
mosaicplot(reproductive.temp,
main = "Drosophila Sterility in Warmer Climates",
color = c('blue', 'yellow'),
xlab = "Country",
ylab = "Number of Reproductive Flies")
install.packages("caret")
install.packages("mlbench")
library(caret)
library(mlbench)
install.packages("caret")
library(caret)
install.packages("data.table")
install.packages("data.table")
library(carat)
library(caret)
library(caret)
library(mlbench)
data(Sonar)
data(Sonar)
set.seed(107)
inTrain <-createDataPartition(y = Sonar$Class,
p=0.75,
list = F)
training <- Sonar[inTrain,]
testing <- Sonar[-inTrain,]
plsFit <- train(Class~.,
method = "pls",
preProc = c("center", "scale"))
plsFit <- train(Class ~ .,
data = training
method = "pls",
preProc = c("center", "scale"))
plsFit <- train(Class ~ .,
data = training
method = "pls",
preProc = c("center", "scale"),
tuneLength = 15)
plsFit <- train(Class ~ .,
data = training,
method = "pls",
preProc = c("center", "scale"),
tuneLength = 15)
install.packages("e1071")
plsFit <- train(Class ~ .,
data = training,
method = "pls",
preProc = c("center", "scale"),
tuneLength = 15)
ctrl <- trainControl(method = "repeatedcv",
repeats = 3)
plsFit <- train(Class ~ .,
data= training,
method = "pls",
preProc = c("center", "scale"),
tuneLength = 15,
trControl = ctrl)
#this modifies the training method to
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = T,
summaryFunction = twoClassSummary)
plsFit <- train(Class ~ .,
data= training,
method = "pls",
preProc = c("center", "scale"),
tuneLength = 15,
trControl = ctrl,
metric = "ROC")
ggplot(plsFit)
plsFit
View(inTrain)
plsFit <- train(Class ~ .,
data= training,
method = "nnet",
preProc = c("center", "scale"),
tuneLength = 15,
trControl = ctrl,
metric = "ROC")
rdaGrid = data.frame(gamma= (0:4)/4, lambda = 3/4)
plsFit <- train(Class ~ .,
data= training,
method = "rda",
preProc = c("center", "scale"),
tuneGrid = rdaGrid,
trControl = ctrl,
metric = "ROC")
plsFit
ggplot(plsFit)
install.packages("dplyr")
# Load the caret package
library(caret)
# Import dataset
orange <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')
# Structure of the dataframe
str(orange)
# See top 6 rows and 10 columns
head(orange[, 1:10])
# Create the training and test datasets
set.seed(100)
##  creating the training data set. Leaving the last 20% for testing
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(orange$Purchase, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- orange[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- orange[-trainRowNumbers,]
# Store X and Y for later use.
x = trainData[, 2:18]
y = trainData$Purchase
# view data
library(skimr)
install.packages("skimr")
# view data
library(skimr)
skimmed <- skim_to_wide(trainData)
skimmed[, c(1:5, 9:11, 13, 15:16)]
##  fill in missing data using impution
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnInpute
install.packages("RANN")
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
##  converting categorical variables to numeric to be used in machine learning
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars(Purchase ~ ., data=trainData)
# Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = trainData)
# Convert to dataframe
trainData <- data.frame(trainData_mat)
# See the structure of the new dataset
str(trainData)
## preprocessing our data by converting all numeric data to be scaled between 0 and 1
preProcess_range_model <- preProcess(trainData, method='range')
trainData <- predict(preProcess_range_model, newdata = trainData)
# Append the Y variable
trainData$Purchase <- y
apply(trainData[, 1:10], 2, FUN=function(x){c('min'=min(x), 'max'=max(x))})
## visualize the importance of certain predictor variables using boxplots
featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "box",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
# In this case, For a variable to be important, I would expect the density curves to be significantly different
# for the 2 classes, both in terms of the height (kurtosis) and placement (skewness).
# Take a look at the density curves of the two categories for 'LoyalCH', 'STORE',
# 'StoreID', 'WeekofPurchase'. Are they different?
featurePlot(x = trainData[, 1:18],
y = trainData$Purchase,
plot = "density",
strip=strip.custom(par.strip.text=list(cex=.7)),
scales = list(x = list(relation="free"),
y = list(relation="free")))
# install.packages('e1071')
library(e1071)
set.seed(100)
options(warn=-1)
subsets <- c(1:5, 10, 15, 18)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(x=trainData[, 1:18], y=trainData$Purchase,
sizes = subsets,
rfeControl = ctrl)
install.packages("randomForest")
set.seed(100)
options(warn=-1)
subsets <- c(1:5, 10, 15, 18)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(x=trainData[, 1:18], y=trainData$Purchase,
sizes = subsets,
rfeControl = ctrl)
lmProfile
modelnames <- paste(names(getModelInfo()), collapse=',  ')
modelnames
modelLookup('earth')
# Set the seed for reproducibility
set.seed(100)
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
fitted <- predict(model_mars)
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
# Train the model using randomForest and predict on the training data itself.
model_mars = train(Purchase ~ ., data=trainData, method='earth')
fitted <- predict(model_mars)
plot(model_mars, main="Model Accuracies with MARS")
varimp_mars <- varImp(model_mars)
plot(varimp_mars, main="Variable Importance with MARS")
# Step 1: Impute missing values
testData2 <- predict(preProcess_missingdata_model, testData)
# Step 2: Create one-hot encodings (dummy variables)
testData3 <- predict(dummies_model, testData2)
# Step 3: Transform the features to range between 0 and 1
testData4 <- predict(preProcess_range_model, testData3)
# View
head(testData4[, 1:10])
# Predict on testData
predicted <- predict(model_mars, testData4)
head(predicted)
# Compute the confusion matrix
confusionMatrix(reference = testData$Purchase, data = predicted, mode='everything', positive='MM')
# Define the training control
fitControl <- trainControl(
method = 'cv',                   # k-fold cross validation
number = 5,                      # number of folds
savePredictions = 'final',       # saves predictions for optimal tuning parameter
classProbs = T,                  # should class probabilities be returned
summaryFunction=twoClassSummary  # results summary function
)
# Step 1: Tune hyper parameters by setting tuneLength
set.seed(100)
model_mars2 = train(Purchase ~ ., data=trainData, method='earth', tuneLength = 5, metric='ROC', trControl = fitControl)
model_mars2
# Step 2: Predict on testData and Compute the confusion matrix
predicted2 <- predict(model_mars2, testData4)
confusionMatrix(reference = testData$Purchase, data = predicted2, mode='everything', positive='MM')
# Step 1: Define the tuneGrid
marsGrid <-  expand.grid(nprune = c(2, 4, 6, 8, 10),
degree = c(1, 2, 3))
# Step 2: Tune hyper parameters by setting tuneGrid
set.seed(100)
model_mars3 = train(Purchase ~ ., data=trainData, method='earth', metric='ROC', tuneGrid = marsGrid, trControl = fitControl)
model_mars3
model_mars2
# Step 3: Predict on testData and Compute the confusion matrix
predicted3 <- predict(model_mars3, testData4)
confusionMatrix(reference = testData$Purchase, data = predicted3, mode='everything', positive='MM')
##  Training Adaboost
set.seed(100)
# Train the model using adaboost
model_adaboost = train(Purchase ~ ., data=trainData, method='adaboost', tuneLength=2, trControl = fitControl)
# Train the model using adaboost
model_adaboost = train(Purchase ~ ., data=trainData, method='adaboost', tuneLength=2, trControl = fitControl)
model_adaboost
##  Training Random Forest
set.seed(100)
# Train the model using rf
model_rf = train(Purchase ~ ., data=trainData, method='rf', tuneLength=5, trControl = fitControl)
model_rf
##  Training xgBoost Dart
set.seed(100)
# Train the model using MARS
model_xgbDART = train(Purchase ~ ., data=trainData, method='xgbDART', tuneLength=5, trControl = fitControl, verbose=F)
setwd("~/Documents/GitHub/datathon2019")
read.csv("pepsi.challenge/shelf-life-study-data-for-analytics-challenge_prediction.csv")
pepsi <- read.csv("pepsi.challenge/shelf-life-study-data-for-analytics-challenge_prediction.csv")
pepsi <- read.csv("pepsi.challenge/shelf-life-study-data-for-analytics-challenge_prediction.csv", row.names=F)
read.csv?
?read.csv
pepsi <- read.csv("pepsi.challenge/shelf-life-study-data-for-analytics-challenge_prediction.csv", as.is=T)
pepsi <- read.csv("pepsi.challenge/pepsi.data.csv")
View(pepsi)
#partition the data (80% test, 20% train)
trainRowNumbers <- createDataPartition(pepsi$Study.Number, p=0.8, list=FALSE)
##  Create the training data set. Leaving the last 20% for testing.
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(pepsi$Study.Number, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- orange[trainRowNumbers,]
# Step 2: Create the training  dataset
trainData <- pepsi[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- pepsi[-trainRowNumbers,]
#load in data
pepsi <- read.csv("pepsi.challenge/pepsi.data.csv", na.strings = "")
View(pepsi)
is.na(pepsi)
num <- 0
badrows <- c()
for(i in 1:nrow(pepsi)){
c <- sum(is.na(pepsi[i,]))
if(c <0.5 * ncol(pepsi)){
num = num +1
badrows <- c(badrows, i)
}
}
for(i in 1:nrow(pepsi)){
c <- sum(is.na(pepsi[i,]))
if(c > 0.5 * ncol(pepsi)){
num = num +1
badrows <- c(badrows, i)
}
}
num <- 0
badrows <- c()
for(i in 1:nrow(pepsi)){
c <- sum(is.na(pepsi[i,]))
if(c > 0.5 * ncol(pepsi)){
num = num +1
badrows <- c(badrows, i)
}
}
pepsi <- pepsi[-badrows,]
numb <- 0
badcols <- c()
for(i in 1:ncols(pepsi)){
c <- sum(is.na(pepsi[,i]))
if(c > 0.5 * nrow(pepsi)){
numb = numb + 1
badcols <- c(badcols, i)
}
}
for(i in 1:ncol(pepsi)){
c <- sum(is.na(pepsi[,i]))
if(c > 0.5 * nrow(pepsi)){
numb = numb + 1
badcols <- c(badcols, i)
}
}
badcols
pepsi <- pepsi[-badcols,]
View(pepsi)
pepsi <- pepsi[,-badcols]
#load in library caret to partition data
library(caret)
##  Create the training data set. Leaving the last 20% for testing.
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(pepsi$Study.Number, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- pepsi[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- pepsi[-trainRowNumbers,]
##  fill in missing data using impution
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnInpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
##  converting categorical variables to numeric to be used in machine learning
# One-Hot Encoding
# Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.
dummies_model <- dummyVars(Purchase ~ ., data=trainData)
View(pepsi)
View(trainData)
#load in data
pepsi <- read.csv("pepsi.challenge/pepsi.data.csv",
na.strings = "",
stringsAsFactors = F)
is.na(pepsi)
#find the rows with more than 50% of the data missing
num <- 0
badrows <- c()
for(i in 1:nrow(pepsi)){
c <- sum(is.na(pepsi[i,]))
if(c > 0.5 * ncol(pepsi)){
num = num +1
badrows <- c(badrows, i)
}
}
#removes the rows that have more than 50% of the data missing
pepsi <- pepsi[-badrows,]
#find the columns with more than 50% of the data missing
numb <- 0
badcols <- c()
for(i in 1:ncol(pepsi)){
c <- sum(is.na(pepsi[,i]))
if(c > 0.5 * nrow(pepsi)){
numb = numb + 1
badcols <- c(badcols, i)
}
}
#removes the columns with more than 50% of the data missing
pepsi <- pepsi[,-badcols]
#load in library caret to partition data
library(caret)
pepsi[is.na(pepsi)] <- "unknown"
View(pepsi)
#random forest to determine which features may be best in predicting
#item freshness
library(e1071)
set.seed(100)
options(warn=-1)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(x=trainData[, 1:12], y=trainData$Difference.From.Fresh,
rfeControl = ctrl)
##  creating the training data set. Leaving the last 20% for testing
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(pepsi$Difference.From.Fresh,
p=0.8,
list=FALSE)
# Step 2: Create the training  dataset
trainData <- pepsi[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- pepsi[-trainRowNumbers,]
#random forest to determine which features may be best in predicting
#item freshness
library(e1071)
set.seed(100)
options(warn=-1)
ctrl <- rfeControl(functions = rfFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(x=trainData[, 1:12], y=trainData$Difference.From.Fresh,
rfeControl = ctrl)
View(trainData)
anyNA(pepsi)
anyNaN(pepsi)
install.packages("checkmate")
library(checkmate)
anyNaN(pepsi)
lmProfile <- rfe(x=trainData[, 1:12], y=trainData$Difference.From.Fresh,
sizes = c(1:12),
rfeControl = ctrl)
lmProfile <- rfe(x=trainData[, 1:12], y=trainData$Difference.From.Fresh,
sizes = c(1:6, 8:12),
rfeControl = ctrl)
